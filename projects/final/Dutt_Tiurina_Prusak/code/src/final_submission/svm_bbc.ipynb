{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import tools as tl\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '../../datasets/BBC News/BBC News Train.csv'  # Replace with your actual file path\n",
    "bbc_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create the test set (735 rows) and training set (remaining rows)\n",
    "test_set = bbc_df.sample(n=735, random_state=42).reset_index(drop=True)  # Test set with 735 samples\n",
    "train_set = bbc_df.drop(test_set.index).reset_index(drop=True)  # Training set with remaining rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 735)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2031</td>\n",
       "      <td>uk young top euro earnings league british chil...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>tech helps disabled speed demons an organisati...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1860</td>\n",
       "      <td>camera phones are  must-haves  four times more...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       2031  uk young top euro earnings league british chil...  business\n",
       "1         76  tech helps disabled speed demons an organisati...      tech\n",
       "2       1860  camera phones are  must-haves  four times more...      tech"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 48/48 [00:46<00:00,  1.04batch/s]\n",
      "Generating Embeddings: 100%|██████████| 46/46 [00:47<00:00,  1.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/87/dhv__9sj0yv1kz0pfv2ds9nh0000gn/T/ipykernel_6932/994341711.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_test = torch.tensor(embeddings_test)\n",
      "/var/folders/87/dhv__9sj0yv1kz0pfv2ds9nh0000gn/T/ipykernel_6932/994341711.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_train = torch.tensor(embeddings_train)\n"
     ]
    }
   ],
   "source": [
    "# Initialize distilroberta tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
    "model = RobertaModel.from_pretrained('distilroberta-base')\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings_train = tl.generate_embeddings(train_set['Text'].tolist(), tokenizer, model)\n",
    "embeddings_test = tl.generate_embeddings(test_set['Text'].tolist(), tokenizer, model)\n",
    "\n",
    "embeddings_test = torch.tensor(embeddings_test)\n",
    "embeddings_train = torch.tensor(embeddings_train)\n",
    "print(\"Embeddings generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an SVM model to the reduced embeddings\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(embeddings_train, train_set['Category'])\n",
    "\n",
    "# Predict the labels\n",
    "predicted_labels = svm_model.predict(embeddings_test)\n",
    "\n",
    "# Add the predicted labels to the dataframe\n",
    "test_set['cluster'] = predicted_labels\n",
    "test_set['embedding'] = embeddings_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('outputs/bbc_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_svm = pd.read_csv('outputs/bbc_svm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.64%\n",
      "F1 Score: 98.64%\n",
      "Precision: 98.65%\n",
      "Recall: 98.64%\n",
      "\n",
      "Detailed Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.99      0.97      0.98       169\n",
      "entertainment       0.99      0.98      0.99       128\n",
      "     politics       0.99      0.99      0.99       140\n",
      "        sport       0.99      1.00      1.00       162\n",
      "         tech       0.96      0.99      0.97       136\n",
      "\n",
      "     accuracy                           0.99       735\n",
      "    macro avg       0.99      0.99      0.99       735\n",
      " weighted avg       0.99      0.99      0.99       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate various classification metrics\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: True labels (actual categories)\n",
    "    y_pred: Predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing various metrics\n",
    "    \"\"\"\n",
    "    # Calculate individual metrics\n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Get detailed classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy * 100,\n",
    "        'f1_score': f1 * 100,\n",
    "        'precision': precision * 100,\n",
    "        'recall': recall * 100,\n",
    "        'detailed_report': report,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Using your existing data\n",
    "metrics = calculate_metrics(\n",
    "    bbc_svm['Category'],\n",
    "    bbc_svm['cluster']\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "print(f\"F1 Score: {metrics['f1_score']:.2f}%\")\n",
    "print(f\"Precision: {metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(metrics['detailed_report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
