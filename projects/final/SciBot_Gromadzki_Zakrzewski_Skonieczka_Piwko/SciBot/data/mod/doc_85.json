{
    "page_content": "**Distributing Computational Budget for Empirical Mean Estimation**\n\n**Questions:**\n\n1. Given a finite computational budget for each algorithm configuration (a limit on the number of runs), how should this budget be allocated across multiple training instances to obtain the most accurate estimate via the empirical mean for some configuration \u03b8?\n2. How many training instances are needed to guarantee an arbitrarily small estimation error with high probability?\n\n**Distributing Computational Budget:**\n\nBirattari (2004) investigated the optimal allocation of a computational budget N for a configuration \u03b8, assuming an infinite set of training instances. The study found that a single run on N problem instances yields the empirical mean estimate with minimal variance. However, this assumption is impractical in real-world applications.\n\n**Generalization to Finite Number of Training Instances:**\n\nLiu et al. (2020) generalized Birattari's result to a more realistic scenario with a finite number of training instances K. They demonstrated that distributing the available computational budget N evenly across all training instances minimizes variance in the empirical mean estimate. Specifically, if each problem instance i should receive ni runs, then ni should be either \u230aN/K\u230b or \u2308N/K\u2309. This distribution scheme is used by algorithm configurators such as ParamILS, irace, and SMAC.",
    "metadata": {
        "source": "../../data/pdfs\\Schede et al. - 2022 - A Survey of Methods for Automated Algorithm Config.pdf",
        "chunk_idx": 69
    }
}