{
    "page_content": "Here is the modified document:\n\n**Influential Factors on Performance Differences between Tree-based Models and Neural Networks**\n\nThis comparison does not account for the fact that each iteration of random search is generally slower for neural networks than for tree-based models (see A.2).\n\nIncluding categorical variables is often cited as a major challenge for using neural networks on tabular data [Borisov et al., 2021]. However, our findings suggest that even when focusing solely on numerical features, there remains a notable gap in performance between tree-based models and neural networks. This disparity persists, albeit to a lesser extent, when excluding categorical variables from the analysis.\n\n**Empirical Investigation: Understanding the Performance Advantage of Tree-based Models**\n\nOur empirical study aimed to elucidate why tree-based models continue to outperform deep learning on tabular data.\n\n**Methodology: Identifying Inductive Biases**\n\nIn Sec. 4.2, we observed that tree-based models surpassed neural networks across a broad range of hyperparameter settings. This observation hints at inherent properties of these models that contribute to their performance advantages on tabular data. Specifically, the best-performing methods for tabular data share two characteristics: they are ensemble methods (bagging or boosting) and employ decision trees as weak learners. While other boosting and bagging methods exist, they are not commonly used for tabular data. In this section, we aim to understand the inductive biases of decision trees that make them well-suited for tabular data and how they differ from those of neural networks.",
    "metadata": {
        "source": "../../data/pdfs\\JP_NeurIPS-2022-why-do-tree-based-models-still-outperform-deep-learning-on-typical-tabular-data-Paper-Datasets_and_Benchmarks.pdf",
        "chunk_idx": 27
    }
}