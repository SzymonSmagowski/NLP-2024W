{
    "page_content": "Here is the rephrased document:\n\nCan We Trust the Bootstrap in High-dimensions?\n\nWhile classical assumptions often assume p/n\u21920, a closer examination reveals that asymptotic predictions based on this high-dimensional assumption can hold surprisingly well even in low-dimensional settings (Johnstone, 2001). Moreover, in these high-dimensional contexts where theoretical understanding is still evolving, the bootstrap emerges as a natural and compelling alternative to traditional asymptotic analysis.\n\nOur investigation also stems from the need to address large-scale applications (Chapelle et al., 2014; Criteo, 2017; Langford et al., 2007), where practitioners often resort to subsampling or recent variants like bag-of-little-bootstraps (Kleiner et al., 2014) for uncertainty assessment. Subsampling is commonly employed in these settings not only for computational efficiency but also to simplify calculations. However, after subsampling, the resulting dataset may exhibit a p/n ratio comparable to that of the original dataset, leading to bootstrap-like computations on subsamples with p comparable to n. Consequently, it becomes crucial to understand whether the bootstrap and other resampling methods perform adequately when p is comparable to n.\n\nDefining success: precise inference on \u03b21 The traditional theoretical benchmark for determining if the bootstrap \"works\" is that the bootstrap distribution of the entire bootstrap estimate \u02c6\u03b2\u2217 converges conditionally almost surely to the sampling distribution of the estimator \u02c6\u03b2.",
    "metadata": {
        "source": "../../data/pdfs\\KS_can_we_trust_in_bootstrap.pdf",
        "chunk_idx": 6
    }
}