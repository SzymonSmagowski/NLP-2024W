{
    "page_content": "Here is the modified document:\n\nAs noted in the preceding discussion leading up to Theorem 3, the fraction of functions resulting in a specified histogram is invariant with respect to the algorithm employed. Consequently, we opt for a straightforward approach to prove the theorem. We consider an ordering of points in the dataset, denoted as , where it is recalled that the histogram is specified by providing the frequencies of occurrence across the respective intervals for each possible cost value. The number of instances under this ordering that yield the desired histogram corresponds directly to the multinomial distribution governing the allocation of cost values.\n\nThe expression for in terms of the entropy of follows from an application of Stirling's approximation, valid when all are large. Specifically, we write the multinomial as: which, upon exponentiation, yields the theorem.\n\nAPPENDIX D\n\nPROOF OF RESULT\n\nIn this appendix, the proportion of algorithms that yield a particular histogram for a given dataset is calculated. The calculation proceeds in several steps:\n\nSince the dataset consists of a finite number of points, there are only a finite number of distinct samples possible. Hence, any (deterministic) algorithm can be represented as an enormous but finite list indexed by all possible datasets . Each entry in this list corresponds to the output that the algorithm produces for the specific -indexed dataset.\n\nLet us consider any particular unordered set of pairs",
    "metadata": {
        "source": "../../data/pdfs\\Wolpert i Macready - 1997 - No free lunch theorems for optimization.pdf",
        "chunk_idx": 58
    }
}