{
    "page_content": "**Instance Generation and Benchmark Selection in Experimental Settings**\n\nIn designing experiments for problem-specific applications with particular requirements and constraints, a meticulous approach to instance generation is essential. To ensure replicability and facilitate further improvements, the generated instances must be thoroughly documented and shared among researchers.\n\nMoreover, creating a benchmark that accurately reflects real-world scenarios is crucial. Practitioners should strive to develop benchmarks that are both realistic and generalizable to various problem contexts. \n\nHowever, when selecting a benchmark for experimentation, careful consideration is necessary to avoid biases inherent in existing literature. Common characteristics of benchmarks include:\n\n\u2022 **Avoidance of centric optima**: To prevent the issues discussed in Section 2.2, it is advisable to position the optimum away from the center of the search domain (e.g., through shifting). Rotation should also be enforced to test the algorithm's sensitivity to coordinate systems.\n\n\u2022 **Sensitivity to local optima**: The presence of multiple local optima in a function is another critical characteristic of a test problem. If not properly addressed in algorithm design, such problems can hinder the convergence of metaheuristics towards the global optimum. In this context, local optima may act as basins of attraction, preventing algorithms from reaching the global optimum unless specifically designed to navigate these challenges.",
    "metadata": {
        "source": "../../data/pdfs\\LaTorre et al. - 2021 - A prescription of methodological guidelines for co.pdf",
        "chunk_idx": 28
    }
}