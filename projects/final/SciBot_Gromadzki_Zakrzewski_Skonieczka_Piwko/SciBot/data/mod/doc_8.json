{
    "page_content": "Here is the modified document:\n\nSMAC employs a target algorithm for exploring combinations of parameter settings and instance features. The predictions generated through this process are then aggregated across instances to provide a statistical performance metric for each parameter configuration.\n\nAdditionally, SMAC utilizes the expected improvement (EI) criterion, as introduced in [46], to identify promising candidate configurations within the parameter space. In contrast to SPO, which performs a single local search, SMAC conducts multiple iterations of simple multi-start local searches to locate configurations with maximal EI and treats all resulting configurations as potential candidates for subsequent iterations.\n\nThrough these primary modifications and enhancements, SMAC is capable of addressing general algorithm parameter tuning problems and achieving superior performance.\n\nAn empirical study comparing the efficacy of SMAC, TB-SPO, GGA, and ParamILS on a range of parameter tuning tasks was conducted in [47]. The objective of this study involved minimizing the runtime of SAT (propositional satisfiability problem) solvers SAOS and SPEAR, as well as MIP (mixed integer programming) solver IBM ILOG CPLEX. The empirical results demonstrated that SMAC consistently yielded statistically significant improvements over the other approaches.\n\nThe source code for SMAC is freely available for download in both Java6 and Python 7 versions. Corresponding documentation can be accessed from the provided websites.\n\nModel-based optimization techniques have been established as efficient solutions for addressing parameter tuning problems. Although SPO has shown the potential and efficiency of model-based tuning, its variants are hindered by two primary limitations:",
    "metadata": {
        "source": "../../data/pdfs\\Huang et al. - 2020 - A Survey of Automatic Parameter Tuning Methods for.pdf",
        "chunk_idx": 64
    }
}